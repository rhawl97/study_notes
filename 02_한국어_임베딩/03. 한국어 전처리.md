## 3.1 데이터 확보

## 3.2 지도 학습 기반 형태소 분석

**0) 형태소**

- 임베딩을 위해서는 문장이나 단어의 경계를 알려줘야 함
- 교착어: 조사와 어미가 발달한 언어
- 형태소 분석: 각 형태소를 단어로 취급해 새로운 '조사+어미'가 등장해도 기존 형태소로 조합할 수 있음
- 태깅: 모델 입력 출력 쌍  ex. 아버지가방에들어가신다 → 아버지, 가, 방, 에, 들어가, 신다

**1) KoNLPy 사용법**

- KoNLPy: 은전한닢, 꼬꼬마, 한나눔, Okt, 코모란 등 5개 오픈소스 형태소 분석기를 통일한 한국어 자연어 처리 패키지
    
    ```python
    from konlpy.tag import Mecab
    tokenizer = Mecab()
    tokenizer.morphs("아버지가방에들어가신다")   #결과: ['아버지', '가', '방', '에', '들어가', '신다']
    ```
    

---

## 3.3 비지도 학습 기반 형태소 분석

**1)  soynlp 형태소 분석기**

- 형태소 분석, 품사 판별 등을 지원하는 패키지
- 사람의 지정이 아니라, 데이터 자체 통계량을 통해 작동
    
    <aside>
    ❓ **응집확률 -** 문자열이 유기적으로 자주 연결되어 나타나는 확률
    **브랜칭 엔트로피 -**  해당 단어 앞뒤로 다양한 조사, 어미, 단어가 등장하는 경우
    
    </aside>
    
- 말뭉치의 통계량을 바탕으로 하기 때문에, 단어별로 응집 확률과 브랜칭 엔트로피 점수표를 만들어줘야 함 (지도 학습 기반 방법과 달리!)
- Ltokenizer: 입력 문장의 왼쪽부터 문자 단위로 슬라이딩해 가며 단어 점수가 높은 문자열을 우선으로 형태소 취급
    
    → 한국어의 특성상, 명사 + 조사 이거나 용언 + 어미 의 형태를 가지므로, 좋은 성능 가능
    

**2) 구글 센텐스피스**

- 구글에서 공개한 비지도 학습 기반 형태소 분석 패키지
- BPE(Byte Pair Encoding): 가장 많이 등장한 문자열을 병합해 압축   ex. aaabdaaabac → ZabdZabac → ZYdZYac
    
    원하는 어휘 집합 크기가 될때까지 반복적으로 고빈도 문자열을 병합 → 어절에 어휘 집합에 있는 서브워드가 포함돼있을 경우 해당 서브워드를 어절에서 분리
    
    BERT 모델 역시 BPE로 학습한 어휘 집합으로 토큰을 분리하는 클래스가 포함되어 있음
    

**3) 띄어쓰기 교정**

- soynlp를 통해 띄어쓰기 교정 → 마찬가지로 단어 점수표 필요
    
    ex. '하자고'라는 문자열 앞뒤로 공백이 다수 발견되었을 때, 동일하게 띄어쓰기 교정
    
- 모델 학습 이전 띄어쓰기 교정을 먼저 적용할 경우, 높은 품질 개선 가능!

---