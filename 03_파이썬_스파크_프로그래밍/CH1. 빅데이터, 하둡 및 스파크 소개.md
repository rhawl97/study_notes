# 1.  빅데이터, 분산 컴퓨팅 및 하둡 소개

## 1) 하둡

**1.1 데이터 지역성**

- 하둡: '데이터 지역성' 개념에 바탕을 둔 데이터 저장 및 처리 플랫폼
- 데이터 지역성
    - 기존 방식 - 요청한 데이터를 원격 처리 시스템이나 호스트로 보내 처리
    - 데이터 지역성 - 데이터가 있는 곳으로 이동해서 계산하는 데이터 처리 방식

**1.2 비공유**

- 하둡은 **비공유** 접근을 사용하는 클러스터의 노드에서 지역적으로 처리될 수 있도록 함
- 각 노드는 다른 노드들과 통신할 필요 x → 전체 데이터의 작은 부분을 독립적으로 처리 = 분산파일시스템의 구현

**1.3 스키마-온-리드**

- 하둡은 기록 연산과 관련된 스키마가 x = **스키마-온-리드**
- 광범위한 데이터를 저장하고 처리할 수 있음(비구조화/반구조화/구조화 데이터 상관없이)
- 하둡에 쓰기 작업을 수행하는 동안에는 해석되지 x → 쿼리 작업이나 클라이언트에 반환되는 데이터 필터링에 최적화

## 2) 하둡의 핵심 구성 요소

**2.1 핵심 구성요소**

- 하둡 분산 파일 시스템(HDFS): 하둡의 스토리지 시스템
- YARN: 하둡의 프로세싱/리소스 스케줄링 시스템

→ 자체 클러스터에서 독립적으로 작동

→ 하둡클러스터 = HDFS 클러스터 + YARN 클러스터

→ 스파크는 두 가지를 모두 활용

- 하둡 에코시스템: Flume, Sqoop, Pig, Hive (데이터 처리 프로젝트, 데이터 분석 툴로, 하둡과 상호작용하거나 통합하는 시스템)

## 3) HDFS: 파일, 블록 및 메타데이터

**3.1 인제션(ingestion)**

- HDFS: 클러스터의 하나 이상의 노드에 파일이 분산돼 있는 블록으로 구성된 가상 파일시스템(클러스터 > 노드 > 블록)
- 인제션: 파일시스템에 데이터를 업로드 → 블록 크기에 따라 RANDOM으로 파일을 나누는 프로세스

**3.2 데이터노드**

- 클러스터 노드 간에 블록을 분산/복제(데이터노드 = 슬레이브노드)
- 데이터노드: 블록 스토리지 관리, 데이터 읽기 및 쓰기, 인제션 프로세스, 블록 복제 관리
- 분산 스파크 worker 노드에 파티션 형식으로 입력 데이터를 제공

**3.3 메타데이터**

- 파일시스템, 가상 디렉토리, 파일, 파일을 구성하는 물리적 블록 → 메타데이터에 저장 → 이게 또 네임노드에 저장
- 네임노드: HDFS 마스터 노드 프로세스의 상주 메모리
- 데이터 읽기
    
    (1) 클라이언트가 HDFS에 파일 읽기 요청
    
    (2) 네임노드: 요청된 파일의 블록이 포함된 데이터노드 목록을 클라이언트에 반환
    
    (3) 클라이언트가 데이터노드와 직접 통신해 데이터블록을 검색
    
- 데이터 쓰기
    
    (1) 클라이언트가 HDFS에 파일 쓰기 요청
    
    (2) 네임노드: 각 블록의 첫번째 복제본을 작성하기 위해 데이터노드 목록을 클라이언트에 반환
    
    (3) 클라이언트: 네임노드가 지정한 데이터노드에 쓴다
    
    (4) 데이터노드: 사이에 복제 파이프라인을 만들고 클라이언트에 알린다
    
    (5) 블록 보고서: 데이터노드 TO 네임노드 → 정기적 전송
    

## 4) YARN을 이용한 응용 스케줄링

**4.1 YARN**

- YARN: 하둡의 데이터 처리를 제어/조율
- 리소스 매니저: 마스터 노드의 데몬
    
    → 클러스터에서 실행 중인 응용 프로그램에 클러스터 컴퓨팅 리소스 부여
    
    → **리소스:  컨테이너 단위(CPU 코어와 메모리 조합)**
    
    → 리소스 부여, 응용프로그램의 상태와 사용 가능한 용량 추적
    
- 노드매니저: 워커/슬레이브 노드에서 실행되는 데몬
- YARN의 역할
    - 리소스 매니저가 노드 매니저를 실행하기 위해 할당한 첫번째 컨테이너로 응용 프로그램 관리에 대해 계획
    - 필요한 리소스를 포함한 응용프로그램(EX. 스파크) 계획
    - 각 단계의 리소스 확보

---

# 2.  아파치 스파크 소개

### 1) 아파치 스파크

**1.1 아파치 스파크**

- 하둡의 맵리듀스 구현체
- 단점: 맵과 리듀스 처리 단계 사이의 중간 데이터가 디스크에 잔류
- 분산형, fault-tolerance, 인메모리 구조
- 스파크는 여러 컴퓨터의 메모리 사용을 극대화 → 성능 향상 → 반복적인 머신 러닝 작업에 효과적

**1.2 스파크 사용**

- 기본적으로 셸에서 대화형 작업
- 비대화형 → *spark-submit* 명령을 통해 제출
- 로컬, s3, 관계형 데이터베이스 시스템, NoSQL, 카프카 등과 함께 사용

**1.3 RDD**

- RDD: 클러스터에 분산된 인메모리 데이터 모음
- 입력데이터를 RDD에 로드 → RDD를 후속 RDD로 변환 → 최종 RDD에서 응용 프로그램의 최종 출력을 저장

---